{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Set the option to display wrapped text\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have the following DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataframe = {\n",
    "    'database': ['db_1', 'db_1', 'db_1', 'db_1'],\n",
    "    'schema': ['schema_1', 'schema_1', 'schema_1', 'schema_1'],\n",
    "    'table': ['table_1', 'table_1', 'table_1', 'table_1'],\n",
    "    'column': ['column_1', 'column_2', 'column_3', 'column_4'],\n",
    "    'th_sum': [\n",
    "        {\n",
    "            'result': 'error',\n",
    "            'reason': 'No matching pattern 1!',\n",
    "            'errror_while_parsing': [1,2,3]\n",
    "        },\n",
    "        np.NaN,\n",
    "        {\n",
    "            'result': 'error',\n",
    "            'reason': 'No matching pattern 2!',\n",
    "            'errror_while_parsing': [1,2,3]\n",
    "        },\n",
    "        np.NaN\n",
    "    ],\n",
    "    'th_null':  [\n",
    "        np.NaN,\n",
    "        {\n",
    "            'result': 'error',\n",
    "            'reason': 'No matching pattern 3!',\n",
    "            'errror_while_parsing': [1,2,3]\n",
    "        },\n",
    "        {\n",
    "            'result': 'error',\n",
    "            'reason': 'No matching pattern 4!',\n",
    "            'errror_while_parsing': [1,2,3]\n",
    "        },\n",
    "        np.NaN\n",
    "    ],\n",
    "    'th_max':  [\n",
    "        np.NaN,\n",
    "        {\n",
    "            'result': 'error',\n",
    "            'reason': 'No matching pattern 5!',\n",
    "            'errror_while_parsing': [1,2,3]\n",
    "        },\n",
    "        {\n",
    "            'result': 'error',\n",
    "            'reason': 'No matching pattern 6!',\n",
    "            'errror_while_parsing': [1,2,3]\n",
    "        },\n",
    "        {\n",
    "            'result': 'error',\n",
    "            'reason': 'No matching pattern 7!',\n",
    "            'errror_while_parsing': [1,2,3]\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "my_dataframe = pd.DataFrame(my_dataframe)\n",
    "th_columns = ['th_sum', 'th_null', 'th_max']\n",
    "my_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_column_name_info(row):\n",
    "    for col_name in th_columns:\n",
    "        if isinstance(row[col_name], dict):\n",
    "            row[col_name]['threshold_where_error_occur'] = col_name\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the custom function to each row\n",
    "df_updated = my_dataframe.apply(add_column_name_info, axis=1)\n",
    "df_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate all threshold into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column with a list of non-null values\n",
    "df_updated['description'] = df_updated[th_columns].apply(lambda row: row[row.notna()].tolist(), axis=1)\n",
    "df_updated = df_updated.drop(columns=th_columns).explode('description').reset_index(drop=True)\n",
    "# Define the keys to extract\n",
    "# keys_to_extract = ['result', 'reason']\n",
    "\n",
    "# # Use apply and pd.Series to create new columns for each key\n",
    "# df_updated[keys_to_extract] = df_updated['description'].apply(lambda x: pd.Series({key: x.get(key) for key in keys_to_extract}))\n",
    "\n",
    "# # Drop the original 'description' column if needed\n",
    "# df = df.drop(columns=['description'])\n",
    "df_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the keys to extract\n",
    "keys_to_extract = ['result', 'reason']\n",
    "# Use apply and pd.Series to create new columns for each key and remove the keys from the original dictionaries\n",
    "df_updated[keys_to_extract] = df_updated['description'].apply(lambda x: pd.Series({key: x.pop(key, None) for key in keys_to_extract}))\n",
    "# Rename column\n",
    "df_updated = df_updated.rename(columns={'description': 'additional information'})\n",
    "\n",
    "# Reorder column\n",
    "# Define the desired column order\n",
    "desired_order = ['database', 'schema', 'table', 'column'] + keys_to_extract + ['additional information']\n",
    "\n",
    "# Reorder columns\n",
    "df_updated = df_updated[desired_order]\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df_updated\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate error in database/schema/table/column and concatenate all errors together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dataframe_with_nulls = {\n",
    "    'database': [np.NaN, np.NaN, 'db_1', 'db_1', np.NaN],\n",
    "    'schema': [np.NaN, np.NaN, 'schema_1', 'schema_1', np.NaN],\n",
    "    'table': [np.NaN, 'table_1', 'table_1', 'table_2', np.NaN],\n",
    "    'column': [np.NaN, 'column_2', np.NaN, 'column_4', np.NaN]\n",
    "}\n",
    "\n",
    "df_common = pd.DataFrame(dataframe_with_nulls)\n",
    "empty_condition = df_common[['database','schema','table','column']].isna().any(axis=1)\n",
    "df_common = df_common[empty_condition]\n",
    "# Add a 'reason' column with a list of values indicating where NaN values occur\n",
    "df_common['description'] = df_common.apply(lambda row: [{'result':'error', 'reason': f'Empty entry found for: {col}'} for col in row.index[row.isna()]], axis=1)\n",
    "df_common = df_common.explode('description')\n",
    "# df_common[['result', 'reason']] = df_common['description'].apply(lambda x: pd.Series(x))\n",
    "# df_common = pd.concat([df_common.drop('description', axis=1), df_common['description'].apply(lambda x: pd.Series(x))], axis=1)\n",
    "df_common = pd.concat([df_common.drop('description', axis=1), \n",
    "                      df_common['description'].apply(lambda x: pd.Series(x)),\n",
    "                      pd.DataFrame(columns=['additional information'])], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df_common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_updated and df_common are your two DataFrames\n",
    "df_combined = pd.concat([df_updated, df_common], axis=0, sort=False)\n",
    "df_combined\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
